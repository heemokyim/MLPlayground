{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Learning\n",
    "\n",
    "## Introduction\n",
    "**Statistical Learning** refers to the vast set of tools for understanging the data. These tools can be classified as *supervised* and *unsupervised*. Broadly speaking, supervised involves building a statistical model for predicting, or estimating, an *output* based on one or more inputs. More generally, suppose that we observe a quantitative response $Y$ and $p$ different predictors, $X_1, X_2,...,X_p$. We assume that there is a relationship between $X$ and $Y$ which can be written in the very general form:\n",
    "\n",
    "$$Y = f(X) + \\epsilon $$\n",
    "\n",
    "Here $f$ is some fixes and unknow function of $X$ and $\\epsilon$ is a random error term independent of $X$ with zero mean. In this formulation $f$ represents the systematic information that $X$ provide about $Y$ and in essence, statistical learning refers to a set of approaches for estimating $f$.\n",
    "\n",
    "There are two main reasons that we may wish to estimate $f$: prediction and inference. In many real-life situtations, a set of input varibles $X$ are readily available, but the output $Y$ cannot be easily obtained. We can predit $Y$ using:\n",
    "\n",
    "$$\\hat{Y} = \\hat f(X) + \\epsilon$$\n",
    "\n",
    "where $\\hat f$ represents or estimating for $f$. However, even if it were possible to form a perfect estimate for $f$, our predictions would still have some error on it. This is because $Y$ is also a function of $\\epsilon$, which by definition, cannot be predicted using $X$. This is known as the *irreducible error*, because no matther how well we estimate $f$, we cannot reduce the error introduced by $\\epsilon$. It easy to hown that:\n",
    "\n",
    "$$\n",
    "\\begin{align*} \n",
    "E(Y-\\hat{Y})^{2} &= E[f(X) + \\epsilon - \\hat f(X))]^{2} \\\\\n",
    "&= [f(X) - \\hat f(X)]^{2} + Var(\\epsilon) \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $E(Y-\\hat{Y})^{2}$ represents the *expected value* of the squared difference between the predicted and expeted value of $Y$ and $Var(\\epsilon)$ represents the variance associated with the error term $\\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bias-Variance Trade-Off\n",
    "The error of $\\hat f$ can always be decomposed into the sum of three fundamental quantities: the variance of $\\hat f(x_0)$, the squared bias of $f(x_0)$ and the variance of the error terms $\\epsilon$. That is,\n",
    "\n",
    "$$expected(MSE) = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat f(x_i)))^2 = E(y_0 - \\hat f(x_0)) \\\\ E(y_0 - \\hat f(x_0))  = Var(\\hat f(x_0)) + [Bias(\\hat f(x_0))]^2 + Var(\\epsilon)$$\n",
    "\n",
    "here, the expected *mean squared srror*, is a way to measure how well its predictions actually match the observed data. That is, we need to quantify the extent to which the predicted response value for a given observation is close to the true response value for that observation. This equation tell us that in order to minimize the expected error, we need to select a statistical learning method that simultaneously achieves *low variance* and *low bias*. Note that the variance and the squared bias are nonnegative and the expected MSE can never lie below $Var(\\epsilon)$.\n",
    "\n",
    "To make it clear, *variance* refers to the amount by which $\\hat f$ would change if we estimated it using a different training data set. Since the training data is used to fit the method, different training data will result in a different $\\hat f$. But ideally, the estimate for $\\hat f$ should not vary too much between training sets. In general, more flexible statistical methods have higher variance.\n",
    "\n",
    "On the other hand, *bias* refers to the error that is introduced by approcimating a real-life problem, which may be extrmely complicated, by a much simpler model. As a general rule, as we use more flexible methods, the variance will increase and the bias will decrease.\n",
    "\n",
    "The relationship between bias, variance and test set MSE is refered as the *bias-variance* tradeoff. The challenge lies in finding a method for which both the variance and the squared bias are low. This trade-off is one of the most important recurring themes in statistical learning.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
